{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRWJMmVfk8yM"
      },
      "source": [
        "# Simple KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5Hn3CdoeII"
      },
      "source": [
        "#### python by package\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fO23kfwojky"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "df.head()\n",
        "X = df.drop('target', axis=1)\n",
        "y = df.target"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD4whQAhvzcL",
        "outputId": "05f7c1c9-f675-4a96-c2c1-4edfbec78ede"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
        "print(X_train.head(2))\n",
        "print(y_train.head(2))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "19                5.1               3.8                1.5               0.3\n",
            "48                5.3               3.7                1.5               0.2\n",
            "19    0\n",
            "48    0\n",
            "Name: target, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF9_oeBMwTvS",
        "outputId": "3c6fa412-c725-4447-840c-41ea1f7240d6"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "knn_c = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_c.fit(X_train, y_train)\n",
        "train_preds = knn_c.predict(X_train)\n",
        "mse = mean_squared_error(y_train, train_preds)\n",
        "rmse = sqrt(mse)\n",
        "rmse"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2041241452319315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um8Xu_lKVNHy",
        "outputId": "76dfdd7f-0798-49b3-f6e4-1836a7aed7c6"
      },
      "source": [
        "knn_c"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yj7B2QZwaaS",
        "outputId": "94aadd71-cae0-48ea-80c1-f8278f4a5269"
      },
      "source": [
        "knn_r = KNeighborsRegressor(n_neighbors=3)\n",
        "knn_r.fit(X_train, y_train)\n",
        "train_preds2 = knn_r.predict(X_train)\n",
        "mse2 = mean_squared_error(y_train, train_preds2)\n",
        "rmse2 = sqrt(mse2)\n",
        "rmse2\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13608276348795434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAqMHtqxVUCT",
        "outputId": "388af263-e8c2-441d-ae68-d0f377ec6283"
      },
      "source": [
        "knn_r"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf41BxItrseK",
        "outputId": "7dacb456-f626-4e39-a2e6-bad99bc549d6"
      },
      "source": [
        "# find the best parameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\"n_neighbors\": range(1, 50)}\n",
        "gridsearch = GridSearchCV(KNeighborsClassifier(), parameters)\n",
        "gridsearch.fit(X_train, y_train)\n",
        "\n",
        "print(\"gridsearch.best_params_\",gridsearch.best_params_)\n",
        "\n",
        "test_preds_grid = gridsearch.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, test_preds_grid)\n",
        "test_rmse = sqrt(test_mse)\n",
        "print(\"KNeighborsClassifier:\",rmse)\n",
        "print(\"GridSearchCV with best k:        \",test_rmse)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gridsearch.best_params_ {'n_neighbors': 5}\n",
            "KNeighborsClassifier: 0.2041241452319315\n",
            "GridSearchCV with best k:         0.18257418583505536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtOLumNpAq03",
        "outputId": "5807ed01-d34b-4f60-ab88-1c1d5f636c70"
      },
      "source": [
        "# Weighted Average of Neighbors Based on Distance\n",
        "parameters = {\n",
        " \"n_neighbors\": range(1, 50),\n",
        " \"weights\": [\"uniform\", \"distance\"]}\n",
        "gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
        "gridsearch.fit(X_train, y_train)\n",
        "\n",
        "print(gridsearch.best_params_)\n",
        "test_preds_grid = gridsearch.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, test_preds_grid)\n",
        "test_rmse2 = sqrt(test_mse)\n",
        "test_rmse2\n",
        "print(\"KNeighborsClassifier:                \",rmse)\n",
        "print(\"GridSearchCV with best               \",test_rmse)\n",
        "print(\"GridSearchCV with best k and weights:\",test_rmse2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': 6, 'weights': 'distance'}\n",
            "KNeighborsClassifier:                 0.2041241452319315\n",
            "GridSearchCV with best                0.18257418583505536\n",
            "GridSearchCV with best k and weights: 0.16546358196238142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebxY1WU30P5N"
      },
      "source": [
        "best_k = gridsearch.best_params_[\"n_neighbors\"]\n",
        "best_weights = gridsearch.best_params_[\"weights\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM9shvPQoX-r"
      },
      "source": [
        "#### from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt-ONXMmkzGX"
      },
      "source": [
        "class simpleKNNClassifier(ClassifierAlgorithm):\n",
        "    \"\"\"\n",
        "    This is a subclass for ClassifierAlgorithm for implementing the  simpleKNN algorithrm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X=None, y=None, split=0.9, k=3):\n",
        "        \"\"\"\n",
        "        The constructor for simpleKNNClassifier subclass.\n",
        "\n",
        "        Parameters:\n",
        "        X: The features of dataset in dataframe format.\n",
        "        y: The label of dataset in dataframe format.\n",
        "        split: The split proportion of the train/test dataset.\n",
        "        k: The number of nearest neighbours (Default = 3)\n",
        "        \"\"\"\n",
        "        self.split = split\n",
        "        if (X is not None) and (y is not None):\n",
        "            self.indices = np.random.permutation(X.shape[0])\n",
        "            self.i = int(X.shape[0] * self.split)\n",
        "        self.k = k\n",
        "\n",
        "    def knn_train(self, X_train=None, y_train=None, X_test=None, y_test=None):\n",
        "        \"\"\"\n",
        "        knn_train:\n",
        "        This method splits the data to train/test datasets random selection.\n",
        "        And build attributes:\n",
        "            X_train, X_test: training/test data of features\n",
        "            y_train, y_test: training/test data of labels\n",
        "        This method also allow the users to input additional splited features/labels.\n",
        "\n",
        "        Parameters:\n",
        "        X_train, X_test, y_train, y_test: (default = None )\n",
        "        \"\"\"\n",
        "        list_input = [X_train, y_train, X_test, y_test]\n",
        "\n",
        "        if all(elem is None for elem in list_input) == True:\n",
        "            # get attributes by random selection.\n",
        "          self.X_train = self.X.iloc[self.indices[:self.i]].reset_index(drop=True)\n",
        "          self.y_train = self.y.iloc[self.indices[:self.i]].rename(\"actual\").reset_index(drop=True)\n",
        "          self.X_test = self.X.iloc[self.indices[self.i:]].reset_index(drop=True)\n",
        "          self.y_test = self.y.iloc[self.indices[self.i:]].rename(\"actual\").reset_index(drop=True)\n",
        "        elif all(elem is not None for elem in list_input[0:3]) == True:\n",
        "            if len(X_train) == len(y_train) and X_train.shape[1] == X_test.shape[1]:\n",
        "                # get attributes by inputs\n",
        "                self.X_train = X_train\n",
        "                self.X_test = X_test\n",
        "                self.y_train = y_train\n",
        "                if y_test is None:\n",
        "                    self.y_test = pd.DataFrame(\"unknown\", index=X_test.index, columns=['actual'])['actual']\n",
        "                elif (len(y_test) == len(X_test)):\n",
        "                    self.y_test = y_test\n",
        "                else:\n",
        "                    raise TypeError(\n",
        "                        \"Invalid input, please input correct dataframes: {X_train, X_test, y_train, y_test}\")\n",
        "            else:\n",
        "                raise TypeError(\"Invalid input, please input correct dataframes: {X_train, X_test, y_train, y_test}\")\n",
        "        else:\n",
        "            raise TypeError(\"Invalid input, please input correct dataframes: {X_train, X_test, y_train, y_test}\")\n",
        "\n",
        "    def Manhattan_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Manhattan_distance:\n",
        "        This method calculates the Manhattan distance between two points\n",
        "\n",
        "        Parameters:\n",
        "        a, b: two points\n",
        "\n",
        "        Returns:\n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate Manhattan distance\n",
        "        for i in range(len(a)):\n",
        "            distance += abs(a[i] - b[i])\n",
        "        return distance\n",
        "\n",
        "    def Euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Euclidean_distance:\n",
        "        This method calculates the Euclidean distance between two points\n",
        "\n",
        "        Parameters:\n",
        "        a, b: two points\n",
        "\n",
        "        Returns:\n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate Manhattan distance\n",
        "        for i in range(len(a)):\n",
        "            distance += (a[i] - b[i]) ** 2\n",
        "        return np.sqrt(distance)\n",
        "\n",
        "    def Chebyshev_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Chebyshev_distance:\n",
        "        This method calculates the Chebyshev distance between two points\n",
        "\n",
        "        Parameters:\n",
        "        a, b: two points\n",
        "\n",
        "        Returns:\n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = []\n",
        "        for i in range(len(a)):\n",
        "            distance.append(abs(a[i] - b[i]))\n",
        "        return max(distance)\n",
        "\n",
        "    def Hamming_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Hamming_distance:\n",
        "        This method calculates the Hamming distance between two categorical points\n",
        "\n",
        "        Parameters:\n",
        "        a, b: two points\n",
        "\n",
        "        Returns:\n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate hamming distance using parameter p\n",
        "        for i in range(len(a)):\n",
        "            if a[i] != b[i]:\n",
        "                distance += 1\n",
        "        return distance\n",
        "\n",
        "    def knn_test(self, method=\"m\"):\n",
        "        \"\"\"\n",
        "        knn_test:\n",
        "        This method predict the labels for x_test dataaset by selected distance calculation method\n",
        "\n",
        "        Parameters:\n",
        "        method :\n",
        "            * \"Manhattan\" or \"m\": compute distance for continuous data by Manhattan_distance method\n",
        "            * \"Euclidean\" or \"e\": compute distance for continuous data  by  Euclidean_distance method\n",
        "            * \"Chebyshev\" or \"c\": compute distance for continuous data by  Chebyshev_distance method\n",
        "            * \"Hamming\"   or \"h\": compute distance for categorical data by  Hamming_distance method\n",
        "\n",
        "        Returns:\n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "\n",
        "        # define the distance method\n",
        "        method = method.lower()\n",
        "        if method == \"manhattan\" or method == \"m\":\n",
        "            dist_function = self.Manhattan_distance\n",
        "        elif method == \"euclidean\" or method == \"e\":\n",
        "            dist_function = self.Euclidean_distance\n",
        "        elif method == \"chebyshev\" or method == \"c\":\n",
        "            dist_function = self.Chebyshev_distance\n",
        "        elif method == \"Hamming\" or method == \"h\":\n",
        "            dist_function = self.Hamming_distance\n",
        "        else:\n",
        "            raise TypeError(\"\"\"Invalid method. The available method contains:\n",
        "                           \\n   * \"Manhattan\" or \"m\": compute distance for continuous  data  by Manhattan_distance method\n",
        "                           \\n   * \"Euclidean\" or \"e\": compute distance for continuous  data  by  Euclidean_distance method\n",
        "                           \\n   * \"Chebyshev\" or \"c\": compute distance for continuous  data  by  Chebyshev_distance method\n",
        "                           \\n   * \"Hamming\"   or \"h\": compute distance for categorical data  by  Hamming_distance method\"\"\")\n",
        "\n",
        "        # compute distance\n",
        "        x_predict = []\n",
        "        for i in self.X_test.index:\n",
        "            distances = []\n",
        "            for j in self.X_train.index:\n",
        "                try:\n",
        "                    distances.append(dist_function(self.X_test.iloc[i], self.X_train.iloc[j, :]))\n",
        "                except:\n",
        "                    raise TypeError(\"\"\"Invalid method. The available method contains:\n",
        "                           \\n   * \"Manhattan\" or \"m\": compute distance for continuous data by Manhattan_distance method\n",
        "                           \\n   * \"Euclidean\" or \"e\": compute distance for continuous data  by  Euclidean_distance method\n",
        "                           \\n   * \"Chebyshev\" or \"c\": compute distance for continuous data by  Chebyshev_distance method\n",
        "                           \\n   * \"Hamming\"   or \"h\": compute distance for categorical data by  Hamming_distance method\"\"\")\n",
        "\n",
        "            # get the top k :short distance\n",
        "            df_dists = pd.DataFrame(data={\"dist\": distances, \"label\": self.y_train},\n",
        "                                    index=self.X_train.index).sort_values(by=['dist'], axis=0)[:self.k]\n",
        "            # get the votes for labels\n",
        "            predict_label = df_dists.label.value_counts()[:1].index.tolist()[0]\n",
        "            # find the final label\n",
        "            x_predict.append(predict_label)\n",
        "\n",
        "        # build the result table\n",
        "        x_test_predict = pd.DataFrame(data={\"predicted\": x_predict}, index=self.X_test.index)\n",
        "        final = self.X_test.merge(self.y_test, left_index=True, right_index=True)\n",
        "        final = final.merge(x_test_predict, left_index=True, right_index=True)\n",
        "        self.knn_result = final[[\"actual\", \"predicted\"]]\n",
        "        return final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GfNZA6lk7ml"
      },
      "source": [
        "class KDNode:\n",
        "    '''\n",
        "    vaule: [X,y]\n",
        "    '''\n",
        "    def __init__(self, value=None, parent=None, left=None, right=None, index=None):\n",
        "        self.value = value\n",
        "        self.parent = parent\n",
        "        self.left = left\n",
        "        self.right = right \n",
        "\n",
        "    @property\n",
        "    def Nodes(self):\n",
        "        \"\"\" \n",
        "        Nodes:\n",
        "        This method updates the nodes\n",
        "\n",
        "        Returns: \n",
        "        value of nodes\n",
        "        \"\"\"      \n",
        "        if not self.parent:\n",
        "            nodes = None\n",
        "        else:\n",
        "            if self.parent.left is self:\n",
        "                nodes = self.parent.right\n",
        "            else:\n",
        "                nodes = self.parent.left\n",
        "        return nodes\n",
        "class kdTreeKNNclassifier(ClassifierAlgorithm):\n",
        "    def __init__(self, X=None,y=None, split=0.9, k=3):\n",
        "        \"\"\" \n",
        "        The constructor for simpleKNNClassifier subclass. \n",
        "  \n",
        "        Parameters: \n",
        "        X: The features of dataset in dataframe format. \n",
        "        y: The label of dataset in dataframe format. \n",
        "        split: The split proportion of the train/test dataset.\n",
        "        k: The number of nearest neighbours (Default = 3)\n",
        "        \"\"\"\n",
        "        super().__init__(X,y, split)\n",
        "        self.root = KDNode()\n",
        "        self.K = k\n",
        "\n",
        "        \n",
        "    def kd_train(self,X_train=None, y_train=None, X_test=None, y_test=None):\n",
        "        \"\"\" \n",
        "        kd_train:\n",
        "        This method splits the data to train/test datasets random selection.\n",
        "        And build attributes:\n",
        "            X_train, X_test: training/test data of features\n",
        "            y_train, y_test: training/test data of labels\n",
        "        This method also allow the users to input additional splited features/labels. \n",
        "\n",
        "        Parameters: \n",
        "        X_train, X_test, y_train, y_test: (default = None )\n",
        "        \"\"\"\n",
        "        list_input = [X_train,y_train,X_test,y_test]\n",
        "\n",
        "        if all(elem is None for elem in list_input) == True:\n",
        "            ClassifierAlgorithm.test(self)\n",
        "            ClassifierAlgorithm.train(self)\n",
        "            self.X_train = self.X_train.to_numpy()\n",
        "            self.X_test = self.X_test.to_numpy()\n",
        "            self.y_train = self.y_train.to_numpy()\n",
        "            self.y_test = self.y_test.to_numpy()\n",
        "        elif all(elem is not None for elem in list_input[0:3]) == True:\n",
        "            if len(X_train) == len(y_train) and X_train.shape[1]==X_test.shape[1]:\n",
        "                self.X_train = X_train.to_numpy()\n",
        "                self.X_test = X_test.to_numpy()\n",
        "                self.y_train = y_train.to_numpy()\n",
        "                if y_test is  None:\n",
        "                    self.y_test = pd.DataFrame(\"unknown\", index=X_test.index, columns=['actual'])['actual']\n",
        "                elif (len(y_test) == len(X_test)):\n",
        "                    self.y_test = y_test.to_numpy()\n",
        "                else:\n",
        "                    raise TypeError(\"Invild input\")\n",
        "            else:\n",
        "                raise TypeError(\"Invild input\")\n",
        "        else:\n",
        "          raise TypeError(\"Invild input\")\n",
        "\n",
        "    def Euclidean_distance(self,a, b):\n",
        "        \"\"\" \n",
        "        Euclidean_distance:\n",
        "        This method calculates the Euclidean distance between two points\n",
        "\n",
        "        Parameters: \n",
        "        a, b: two points\n",
        "        \n",
        "        Returns: \n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate minkowski distance using parameter p = 2\n",
        "        for i in range(len(a)):\n",
        "            distance += (a[i] - b[i])**2\n",
        "        return np.sqrt(distance)\n",
        "\n",
        "    def Chebyshev_distance(self,a, b):\n",
        "        \"\"\" \n",
        "        Chebyshev_distance:\n",
        "        This method calculates the Chebyshev distance between two points\n",
        "\n",
        "        Parameters: \n",
        "        a, b: two points\n",
        "        \n",
        "        Returns: \n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = []\n",
        "        for i in range(len(a)):\n",
        "            distance.append( abs(a[i] - b[i]))\n",
        "        return max(distance)\n",
        "    \n",
        "    def Hamming_distance(self,a, b):\n",
        "        \"\"\" \n",
        "        Hamming_distance:\n",
        "        This method calculates the Hamming distance between two points\n",
        "\n",
        "        Parameters: \n",
        "        a, b: two points\n",
        "        \n",
        "        Returns: \n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate hamming distance using parameter p\n",
        "        for i in range(len(a)):\n",
        "          if a[i] != b[i]:\n",
        "            distance += 1\n",
        "        return distance\n",
        "\n",
        "    def Manhattan_distance(self,a, b): \n",
        "        \"\"\" \n",
        "        Manhattan_distance:\n",
        "        This method calculates the Manhattan distance between two points\n",
        "\n",
        "        Parameters: \n",
        "        a, b: two points\n",
        "        \n",
        "        Returns: \n",
        "        distances: The distance between two points\n",
        "        \"\"\"\n",
        "        # Set initial distance to 0\n",
        "        distance = 0\n",
        "        # Calculate minkowski distance using parameter p =1\n",
        "        for i in range(len(a)):\n",
        "            distance += abs(a[i] - b[i])\n",
        "        return distance\n",
        "\n",
        "    def build_tree(self, data, axis=0,parent=None):\n",
        "        \"\"\" \n",
        "        build_tree:\n",
        "        This method build kd tree for trainng dataset\n",
        "\n",
        "        Parameters: \n",
        "        data: training dataset\n",
        "        axis: axis\n",
        "        parent: parent node\n",
        "        \n",
        "        Returns: \n",
        "        root: The nodes of tree\n",
        "        \"\"\"\n",
        "\n",
        "        # choose median point \n",
        "        if len(data) == 0:\n",
        "            root = KDNode()\n",
        "            return root\n",
        "        data = np.array(sorted(data, key=lambda x:x[axis]))\n",
        "        #get median\n",
        "        median = int(len(data)/2)\n",
        "\n",
        "        root = KDNode(data[median],parent=parent)\n",
        "        #depth+1\n",
        "        new_axis = (axis+1)%(len(data[0])-1)\n",
        "        # spliting into partitions\n",
        "        left = data[:median,:]\n",
        "        right = data[median+1:,:]\n",
        "\n",
        "        #While (P != null) \n",
        "        if len(left) != 0:\n",
        "          root.left = self.build_tree(left,axis=new_axis,parent=root)\n",
        "        else:\n",
        "          root.left = None\n",
        "        if len(right) != 0:\n",
        "          root.right = self.build_tree(right,axis=new_axis,parent=root)\n",
        "        else:\n",
        "          root.right = None\n",
        "          \n",
        "        self.root = root \n",
        "\n",
        "        return root\n",
        "    \n",
        "    def kd_tree(self):\n",
        "        \"\"\" \n",
        "        kd_tree:\n",
        "        This method implement the method build_tree\n",
        "        \"\"\"\n",
        "        X = self.X_train\n",
        "        y = self.y_train\n",
        "        data = np.concatenate([X, y.reshape(-1,1)],axis=1)\n",
        "        root = self.build_tree(data)\n",
        "\n",
        "    def search_tree(self,point,dist_function ):\n",
        "        \"\"\" \n",
        "        search_tree:\n",
        "        This method  traverse through the tree and find K nearest points\n",
        "\n",
        "        Parameters: \n",
        "        point: the point that need to be classfied\n",
        "        dist_function : the function that compute the distance\n",
        "\n",
        "        Returns: \n",
        "        dist_table: The dataframe of K nearest points\n",
        "        \"\"\"\n",
        "        self.kd_tree()\n",
        "        loc = self.root\n",
        "        # init the leaf node\n",
        "        axis = 0\n",
        "        while loc:\n",
        "            if point[axis] < loc.value[axis]:\n",
        "                temp = loc\n",
        "                loc = loc.left\n",
        "            else:\n",
        "                temp = loc\n",
        "                loc = loc.right\n",
        "            axis = (axis+1)%len(point)\n",
        "        current = temp\n",
        "     \n",
        "        class_y = []\n",
        "        dist = []\n",
        "        #  traverse through the tree \n",
        "        while current:\n",
        "            node_dist = dist_function(current.value[:-1],point)\n",
        "            dist.append(node_dist)\n",
        "            class_y.append(current.value[-1])\n",
        "            if current.Nodes:\n",
        "                node_dist = dist_function(current.Nodes.value[:-1],point)\n",
        "                dist.append(node_dist)\n",
        "                class_y.append(current.Nodes.value[-1])\n",
        "            current = current.parent\n",
        "        \n",
        "        dist_table = pd.DataFrame(data={\"dist\":dist,\"label\":class_y}).sort_values(by=['dist'], axis=0)\n",
        "        dist_table = dist_table[:self.K]\n",
        "        return dist_table\n",
        "        \n",
        "    def kd_test(self,method = \"e\"):\n",
        "        \"\"\" \n",
        "        kd_test:\n",
        "        This method predict the labels for x_test dataaset by selected distance calculation method\n",
        "\n",
        "        Parameters: \n",
        "        method :\n",
        "            * \"Manhattan\" or \"m\": compute distance for continuous data by Manhattan_distance method\n",
        "            * \"Euclidean\" or \"e\": compute distance for continuous data  by  Euclidean_distance method\n",
        "            * \"Chebyshev\" or \"c\": compute distance for continuous data by  Chebyshev_distance method\n",
        "            * \"Hamming\"   or \"h\": compute distance for categorical data by  Hamming_distance method\n",
        "\n",
        "        Returns: \n",
        "        kd_result: the dataframe of predicted result and the actual result\n",
        "        \"\"\"\n",
        "        predict = [0 for i in range(len(self.X_test))]\n",
        "\n",
        "        method = method.lower()\n",
        "        if method == \"manhattan\" or method == \"m\" :\n",
        "          dist_function = self.Manhattan_distance\n",
        "        elif method == \"euclidean\"or method == \"e\"  : \n",
        "          dist_function = self.Euclidean_distance\n",
        "        elif method == \"chebyshev\"or method == \"c\"  :\n",
        "          dist_function = self.Chebyshev_distance\n",
        "        elif method == \"Hamming\"or method == \"h\"  :\n",
        "          dist_function = self.Hamming_distance\n",
        "        else:\n",
        "          raise TypeError(\"invalid method\")\n",
        "        \n",
        "\n",
        "        for i in range(len(self.X_test)):\n",
        "            dist_table = self.search_tree(self.X_test[i],dist_function = dist_function)\n",
        "            dist_table[\"label\"] = dist_table[\"label\"].astype(\"category\")\n",
        "            predict_label = dist_table.label.value_counts()[:1].index.tolist()[0]\n",
        "            predict[i] = predict_label\n",
        "        self.kd_result = pd.DataFrame(data={\"predicted\":predict,\"actual\":self.y_test})\n",
        "        return self.kd_result\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}