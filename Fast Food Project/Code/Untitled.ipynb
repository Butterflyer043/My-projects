{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Student1  Student2  Student3\n",
      "Grade1      89.3      77.3      97.1\n",
      "Grade2      78.7      83.4      88.6\n",
      "Grade3      92.2      91.8      98.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#1.手动输入\n",
    "gradebook={\n",
    "        \"Student1\": pd.Series([89.3, 78.7, 92.2], index=['Grade1', 'Grade2', 'Grade3']),\n",
    "        \"Student2\": pd.Series([77.3, 83.4, 91.8], index=['Grade1', 'Grade2', 'Grade3']),\n",
    "        \"Student3\": pd.Series([97.1, 88.6, 98.5], index=['Grade1', 'Grade2', 'Grade3'])\n",
    "        }\n",
    "gradeBookDF=pd.DataFrame(gradebook) \n",
    "print(gradeBookDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bob Smith Sandy Stern\n",
      "G1       NaN         NaN\n",
      "G2       NaN         NaN\n",
      "G3       NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "#Create an empty dataframe 创建一个空df\n",
    "Gradebook2 = pd.DataFrame(index=['G1', 'G2', 'G3'], \n",
    "                          columns=['Bob Smith', 'Sandy Stern'])\n",
    "print(Gradebook2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in values\n",
    "Gradebook2.loc[\"G1\",\"Bob Smith\"]=98.1\n",
    "print(Gradebook2)\n",
    "#   Bob Smith Sandy Stern\n",
    "#G1      98.1         NaN\n",
    "#G2       NaN         NaN\n",
    "#G3       NaN         NaN\n",
    "\n",
    "#Create a new column\n",
    "Gradebook2[\"NewColumn\"]=\"NaN\"\n",
    "print(Gradebook2)\n",
    "\n",
    "import random\n",
    "for i in Gradebook2.index:\n",
    "    print(i)\n",
    "    Gradebook2.loc[i,\"Bob Smith\"]=random.randint(50,100)\n",
    "    #print(Gradebook2)\n",
    "print(Gradebook2)\n",
    "\n",
    "#2. convert from other type\n",
    "MyDict=[{\"Name\":\"Bob\", \"Age\":29, \"Degree\":\"MS\"}, {\"Name\":\"Rob\", \"Age\":34, \"Degree\":\"PhD\"}]\n",
    "DictDF=pd.DataFrame.from_dict(MyDict)\n",
    "DictDF.insert(2, 'NewColumn', [20007, 23604])\n",
    "#REMOVE the “Degree” column\n",
    "DictDF=DictDF.drop(\"Degree\", axis=1)\n",
    "#axis=1 is the column, axis=0 is the row\n",
    "#Remove the first row (row 0)\n",
    "DictDF=DictDF.drop(0)\n",
    "print(DictDF)\n",
    "\n",
    "#3. import data from csv\n",
    "stu_df = pd.read_csv ('StudentData2.csv')\n",
    "\n",
    "######### cleaning data\n",
    "#convert the type of column id to string\n",
    "stu_df.id = stu_df.id.astype (str) \n",
    "   # stu_df.id.astype (\"category\")\n",
    "   #or df.Sex = pd.Categorical(df.Sex) # \n",
    "#Remove rows with IDs that are not 6 in length.\n",
    "stu_df = stu_df[stu_df.id.map(len)==6] \n",
    "#Remove rows with genders other than 1 or 2.\n",
    "stu_df = stu_df[(stu_df['gender']==1)|(stu_df['gender']==2 )]\n",
    "#Remove rows with ages outside of range.[18,80]\n",
    "stu_df = stu_df[(stu_df['age']>=18)&(stu_df['age']<=80)] \n",
    "#Remove rows with incorrect or missing gpa values.\n",
    "stu_df = stu_df[(stu_df['gpa']>=float(0))&(stu_df['gpa']<=float(4.00))] \n",
    "#Remove rows with sat missing or out of range [0,1600].\n",
    "stu_df = stu_df[(stu_df.sat>=0)&(stu_df.sat<=1600)] \n",
    "#Remove rows with sections that are missing.\n",
    "stu_df = stu_df[stu_df['section'].notnull()]\n",
    "#Remove rows with any incorrect or missing values of final\n",
    "stu_df = stu_df[(stu_df.final>=0)&(stu_df.final<=100)] \n",
    "#Remove rows with any incorrect or missing values of final\n",
    "stu_df = stu_df[(stu_df.project>=0)&(stu_df.project<=100)] \n",
    "\n",
    "#找出有空值得col\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "#replace NaN to 0\n",
    "df=df.fillna(0) \n",
    "\n",
    "#change type\n",
    "#df.Items =  df.Items.astype ('category') \n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "bins = [0,2,2.5,3,3.5,4]\n",
    "labels = ['F','D','C','B','A']\n",
    "stu_df['binned'] = pd.cut(stu_df['gpa'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) #\n",
    "\n",
    "# =============================================================================\n",
    "# # t-test for independent samples\n",
    "# =============================================================================\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    "\n",
    "# function for calculating the t-test for two independent samples\n",
    "def independent_ttest(data1, data2, alpha):\n",
    "\t# calculate means\n",
    "\tmean1, mean2 = mean(data1), mean(data2)\n",
    "\t# calculate standard errors\n",
    "\tse1, se2 = sem(data1), sem(data2)\n",
    "\t# standard error on the difference between the samples\n",
    "\tsed = sqrt(se1**2.0 + se2**2.0)\n",
    "\t# calculate the t statistic\n",
    "\tt_stat = (mean1 - mean2) / sed\n",
    "\t# degrees of freedom\n",
    "\tdf = len(data1) + len(data2) - 2\n",
    "\t# calculate the critical value\n",
    "\tcv = t.ppf(1.0 - alpha, df)\n",
    "\t# calculate the p-value\n",
    "\tp = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "\t# return everything\n",
    "\treturn t_stat, df, cv, p\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# calculate the t test\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = independent_ttest(data1, data2, alpha)\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))\n",
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# =============================================================================\n",
    "# R_Squared    \n",
    "# =============================================================================\n",
    "### Method 1\n",
    "from statistics import mean\n",
    "# R^2 = SSR / SST\n",
    "# create function that calculate regression line (Yi_hat = b0+b1*Xi) for y_hat \n",
    "def reg_line (x,y): # x = variable 1, y = variable 2\n",
    "    n = len(x) # n = sample size\n",
    "    xbar = mean(x)\n",
    "    ybar = mean(y)\n",
    "    b1 = (sum(x*y)-n*xbar*ybar)/(sum(x**2)-n*xbar**2)\n",
    "    b0 = ybar - b1 * xbar\n",
    "    return (b0,b1)\n",
    "# create function that calculate R squared\n",
    "def R_Squared (x,y):\n",
    "    #run the function of regression line \n",
    "    b0,b1 = reg_line(x,y)\n",
    "    #get y_hat series\n",
    "    yhat = b0 + b1*x\n",
    "    ybar = mean(y)\n",
    "    #calculate SSR   \n",
    "    SSR = sum((yhat - ybar)**2)\n",
    "    #calculate SST\n",
    "    SST = sum((y-ybar)**2)\n",
    "    #calculate R value\n",
    "    R_squared = SSR/SST\n",
    "    return R_squared\n",
    "#R_values= math.sqrt(R_Squared (x,y) ) \n",
    "    \n",
    "### Method 2\n",
    "np.corrcoef(x,y)\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ANOVA\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "datafile = \"PlantGrowth.csv\"\n",
    "data = pd.read_csv('PlantGrowth.csv')\n",
    "\n",
    "#Create a boxplot\n",
    "#data.boxplot('weight', by='group', figsize=(12, 8))\n",
    "\n",
    "\n",
    "grps = pd.unique(data.group.values)\n",
    "d_data = {grp:data['weight'][data.group == grp] for grp in grps}\n",
    "\n",
    "k = len(pd.unique(data.group))  # number of conditions\n",
    "N = len(data.values)  # conditions times participants\n",
    "n = data.groupby('group').size()[0] #Participants in each condition\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "F, p = stats.f_oneway(d_data['ctrl'], d_data['trt1'], d_data['trt2'])\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# DFbetween = k - 1\n",
    "# DFwithin = N - k\n",
    "# DFtotal = N - 1\n",
    "# SSbetween = (sum(data.groupby('group').sum()['weight']**2)/n) -(data['weight'].sum()**2)/N\n",
    "# sum_y_squared = sum([value**2 for value in data['weight'].values])\n",
    "# SSwithin = sum_y_squared - sum(data.groupby('group').sum()['weight']**2)/n\n",
    "# SStotal = sum_y_squared - (data['weight'].sum()**2)/N\n",
    "# MSbetween = SSbetween/DFbetween\n",
    "# MSwithin = SSwithin/DFwithin \n",
    "# F2 = MSbetween/MSwithin\n",
    "# p2 = stats.f.sf(F, DFbetween, DFwithin)\n",
    "# ==========================\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# 重点！！！！ group的type一定要是“\n",
    "data.dtypes\n",
    "data.group = data.group.astype ('category') \n",
    "mod = ols('weight ~ group', data=data).fit()           \n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print (aov_table)\n",
    "# ==========================\n",
    "# >>> import random\n",
    "#>>> random.seed(0)\n",
    "#>>> data = [[random.randint(1, 20) for _ in range(size)] for size in range(1, 5)]\n",
    "#>>> for sample in data:\n",
    "#...     print(sample)\n",
    "#[13]\n",
    "#[14, 2]\n",
    "#[9, 17, 16]\n",
    "#[13, 10, 16, 12]\n",
    "#\n",
    "#We see that we have 4 samples of different size. Here let’s carry out the ANOVA:\n",
    "#\n",
    "#>>> from scipy import stats\n",
    "#>>> f_val, p_val = stats.f_oneway(*data)\n",
    "#>>> p_val\n",
    "#0.57172146848075944   \n",
    "# ==========================  \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# =============================================================================\n",
    "# visualization\n",
    "# =============================================================================\n",
    "\n",
    "# https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/#17.-Dot-Plot\n",
    "    \n",
    "    \n",
    "    \n",
    "#To reject the null hypothesis we check if the obtained F-value is \n",
    "#above the critical value for rejecting the null hypothesis. We could \n",
    "#look it up in a F-value table based on the DFwithin and DFbetween\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
